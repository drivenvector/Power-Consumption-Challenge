# 2 Loading packages
pkgs <- c("tidyverse", "caret","zoo", "mice", 'VIM')
lapply(pkgs, require, character.only= TRUE)
lapply(pkgs, require, character.only= TRUE)
setwd("D:/Technical/Driven Data Competition")
# 2 Loading packages
pkgs <- c("tidyverse", "caret","zoo", "mice", 'VIM')
lapply(pkgs, require, character.only= TRUE)
# 3 Importing data
meta <- read.csv('datasets/meta.csv')
train <- read.csv('datasets/consumption_train.csv')
test <- read.csv('datasets/cold_start_test.csv')
# 2 Loading packages
pkgs <- c("tidyverse", "caret","zoo", "mice", 'VIM', 'e1071')
lapply(pkgs, require, character.only= TRUE)
# 2 tidying meta data
# Converting dummy variable for surface
# meta_data_spread <- meta %>%  spread(key = surface, value = surface)
# View(meta_data_spread)
View(head(meta))
meta<- meta %>%
mutate(v = 1, sf = surface) %>%
spread(sf, v, fill = 0)
# 2 tidying meta data
# Converting dummy variable for surface
# meta_data_spread <- meta %>%  spread(key = surface, value = surface)
# View(meta_data_spread)
View(head(meta))
meta$surface <- NULL  # Removing the surface variable
# 2 tidying meta data
# Converting dummy variable for surface
# meta_data_spread <- meta %>%  spread(key = surface, value = surface)
# View(meta_data_spread)
View(head(meta))
# 3 Renaming dummy columns from surface
meta <- meta %>% rename(is_large = large)        # large
# 2 tidying meta data
# Converting dummy variable for surface
# meta_data_spread <- meta %>%  spread(key = surface, value = surface)
# View(meta_data_spread)
View(head(meta))
meta <- meta %>% rename(is_medium = medium)      # medium
meta <- meta %>% rename(is_Xlarge = 'x-large')   # xlarge
meta <- meta %>% rename(is_Xsmall = 'x-small')   # x small
meta <- meta %>% rename(is_XXlarge = 'xx-large') # xx-large
meta <- meta %>% rename(is_XXsmall = 'xx-small') # xx-small
meta <- meta %>% rename(is_small = small)        # small
meta <- meta %>% rename(is_baseTemperatureHigh = base_temperature) # base Temperature
View(meta)
meta$is_baseTemperatureHigh <- if_else(meta$is_baseTemperatureHigh == 'high', 1, 0)
table(meta_data_spread$is_baseTemperatureHigh)
table(meta$is_baseTemperatureHigh)
# 5 Converting NAs to 0 and their own value to 1
meta$is_large   <- if_else(is.na(meta$is_large), 0, 1)
meta$is_medium  <- if_else(is.na(meta$is_medium), 0, 1)
meta$is_Xlarge  <- if_else(is.na(meta$is_Xlarge), 0, 1)
meta$is_Xsmall  <- if_else(is.na(meta$is_Xsmall), 0, 1)
meta$is_XXsmall <- if_else(is.na(meta$is_XXsmall), 0, 1)
meta$is_small   <- if_else(is.na(meta$is_small), 0, 1)
meta$is_XXlarge <- if_else(is.na(meta$is_XXlarge), 0, 1)
View(head(meta, 10))
# 6 Converting False to 0 and True to 1 in days columns
meta$monday_is_day_off    <- if_else(meta$monday_is_day_off=="False", 0, 1)
meta$tuesday_is_day_off   <- if_else(meta$tuesday_is_day_off=="False", 0, 1)
meta$wednesday_is_day_off <- if_else(meta$wednesday_is_day_off=="False", 0, 1)
meta$thursday_is_day_off  <- if_else(meta$thursday_is_day_off =="False", 0, 1)
meta$friday_is_day_off    <- if_else(meta$friday_is_day_off=="False", 0, 1)
meta$saturday_is_day_off  <- if_else(meta$saturday_is_day_off=="False", 0, 1)
meta$sunday_is_day_off    <- if_else(meta$sunday_is_day_off=="False", 0, 1)
View(head(meta, 10))
# 7 Looking at data tidified till now
sapply(meta_data_spread[-1],  table)
# 7 Looking at data tidified till now
sapply(meta[-1],  table)
str(meta)
sapply(meta, typeof)
# 8 Convert the numeric datatype of meta data to factorial except series_id
test_meta <- meta_data_spread %>% select(-series_id) %>% mutate_if(is.numeric, as.factor)
# 8 Convert the numeric datatype of meta data to factorial except series_id
meta <- meta %>% select(-series_id) %>% mutate_if(is.numeric, as.factor)
str(test_meta)
str(meta)
sapply(meta, typeof)
str(meta)
rm(meta)
# 3 Importing data
meta <- read.csv('datasets/meta.csv')
meta<- meta %>%
mutate(v = 1, sf = surface) %>%
spread(sf, v, fill = 0)
meta$surface <- NULL  # Removing the surface variable
# 3 Renaming dummy columns from surface
meta <- meta %>% rename(is_large = large)        # large
meta <- meta %>% rename(is_medium = medium)      # medium
meta <- meta %>% rename(is_Xlarge = 'x-large')   # xlarge
meta <- meta %>% rename(is_Xsmall = 'x-small')   # x small
meta <- meta %>% rename(is_XXlarge = 'xx-large') # xx-large
meta <- meta %>% rename(is_XXsmall = 'xx-small') # xx-small
meta <- meta %>% rename(is_small = small)        # small
meta <- meta %>% rename(is_baseTemperatureHigh = base_temperature) # base Temperature
meta$is_baseTemperatureHigh <- if_else(meta$is_baseTemperatureHigh == 'high', 1, 0)
# 5 Converting NAs to 0 and their own value to 1
meta$is_large   <- if_else(is.na(meta$is_large), 0, 1)
meta$is_medium  <- if_else(is.na(meta$is_medium), 0, 1)
meta$is_Xlarge  <- if_else(is.na(meta$is_Xlarge), 0, 1)
meta$is_Xsmall  <- if_else(is.na(meta$is_Xsmall), 0, 1)
meta$is_XXsmall <- if_else(is.na(meta$is_XXsmall), 0, 1)
meta$is_small   <- if_else(is.na(meta$is_small), 0, 1)
meta$is_XXlarge <- if_else(is.na(meta$is_XXlarge), 0, 1)
# 6 Converting False to 0 and True to 1 in days columns
meta$monday_is_day_off    <- if_else(meta$monday_is_day_off=="False", 0, 1)
meta$tuesday_is_day_off   <- if_else(meta$tuesday_is_day_off=="False", 0, 1)
meta$wednesday_is_day_off <- if_else(meta$wednesday_is_day_off=="False", 0, 1)
meta$thursday_is_day_off  <- if_else(meta$thursday_is_day_off =="False", 0, 1)
meta$friday_is_day_off    <- if_else(meta$friday_is_day_off=="False", 0, 1)
meta$saturday_is_day_off  <- if_else(meta$saturday_is_day_off=="False", 0, 1)
meta$sunday_is_day_off    <- if_else(meta$sunday_is_day_off=="False", 0, 1)
# 8 Convert the numeric datatype of meta data to factorial except series_id
metaseries <- meta$series_id
meta <- meta %>% select(-series_id) %>% mutate_if(is.numeric, as.factor)
str(meta)
meta <- cbind(meta_data_spread$series_id, metaseries)
meta <- cbind(meta, metaseries)
str(meta)
meta <- meta %>% rename(series_id = 'metaseries')
View(meta)
colnames(meta)
str(train)  # 509376 obs. of  5 variables
str(test)   # 111984 obs. of  5 variables
str(test)   # 111984 obs. of  5 variables
View(head(train))
View(head(test))
# 9 Data cleaning in train and test sets
train$X <- NULL
test$X <- NULL
View(head(train))
write(meta, file = "./processed/meta")
write(meta, file = "./processed/meta.data")
write(meta, file = "./processed/meta.csv")
saveRDS(meta, file = "./processed/meta.rds")
install.packages('xts')
install.packages('xts', dependencies = TRUE, repos = 'https://cran.rstudio.com')
install.packages('xts', dependencies = TRUE, repos = 'http://cran.rstudio.com/')
# 2 Loading packages
pkgs <- c("tidyverse", "caret","zoo", "mice", 'VIM', 'e1071')
library(xts)
datetime_test <- train[1:10, 'timestamp']
View(datetime_test)
str(datetime_test)
datetime_test_strptime <- strptime(datetime_test, format = "%Y-%m-%d %H:%M:%S")
str(datetime_test)
str(datetime_test_strptime)
str(train)
# Converting datatype of timestamp from character factor to POSIXit using strptime
train$timestamp <- strptime(train$timestamp, format = "%Y-%m-%d %H:%M:%S")
str(train)
test$timestamp <- strptime(test$timestamp, format = "%Y-%m-%d %H:%M:%S")
str(test)
# splitting timestamp into date and in time and extracting the hour part from time
train$date <- as.Date(train$timestamp)
str(train)
train$time <- format(as.POSIXct(train$timestamp) ,format = "%H:%M:%S")
str(train)
?hour
train$hour <- hour(train$timestamp, format = "%Y-%m-%d %H:%M:%S")
train$hour <- hour(train$time) #stamp, format = "%Y-%m-%d %H:%M:%S")
train$hour <- hour(train$time, format = "%H:%M:%S") #stamp, format = "%Y-%m-%d %H:%M:%S")
train$hour <- hour(hms(train$time, format = "%H:%M:%S")) #stamp, format = "%Y-%m-%d %H:%M:%S")
train$hour <- hour(hms(as.character(train$time), format = "%H:%M:%S")) #stamp, format = "%Y-%m-%d %H:%M:%S")
train$hour <- hour(hms(as.character(train$time))) #stamp, format = "%Y-%m-%d %H:%M:%S")
sessionInfo()
library(lubridate)
sessionInfo()
train$hour <- hour(hms(as.character(train$time))) #stamp, format = "%Y-%m-%d %H:%M:%S")
str(train$hour)
str(train)
table(train$hour)
typeof(train$hour)
View(head(train))
#test data
test$date <- as.Date(test$timestamp)
test$time <- format(as.POSIXct(test$timestamp) ,format = "%H:%M:%S")
test$hour <- hour(hms(as.character(test$time)))
str(test)
str(train)
train$time <- NULL
test$time <- NULL
View(head(train))
# train and test data has been processed till this point. Lets save it so it saves time in future
# Save an object to a file
saveRDS(train, file = "./processed/train.rds")
saveRDS(test, file = "./processed/test.rds")
rm(datetime_test_strptime)
rm(datetime_test)
train_ts <- xts(x = train, order.by = train$timestamp)
# 10 left join between train and meta
train_meta_lj <- left_join(x= train, y = meta, suffix = c(".x", ".m1"))
# Difference between postixit and posixct:
# https://stackoverflow.com/questions/10699511/difference-between-as-posixct-as-posixlt-and-strptime-for-converting-character-v
# https://data.library.virginia.edu/working-with-dates-and-time-in-r-using-the-lubridate-package/
datetime_test <- train[1:10, 'timestamp']
str(datetime_test)
datetime_test_strptime <- as.POSIXct(datetime_test_strptime)
# Difference between postixit and posixct:
# https://stackoverflow.com/questions/10699511/difference-between-as-posixct-as-posixlt-and-strptime-for-converting-character-v
# https://data.library.virginia.edu/working-with-dates-and-time-in-r-using-the-lubridate-package/
datetime_test <- train[1:10, 'timestamp']
datetime_test_strptime <- strptime(datetime_test, format = "%Y-%m-%d %H:%M:%S")
str(datetime_test_strptime)
datetime_test_strptime <- as.POSIXct(datetime_test_strptime)
str(datetime_test_strptime)
# 10 left join between train and meta
train_meta_lj <- left_join(x= train, y = meta, suffix = c(".x", ".m1"))
train_for_timestamp <- read.csv('datasets/consumption_train.csv')
train_for_timestamp <- read.csv('datasets/consumption_train.csv')
train_for_timestamp <- read.csv('datasets/consumption_train.csv')
train_for_timestamp <- as.POSIXct(train$timestamp)
train_for_timestamp$timestamp <- as.POSIXct(train_for_timestamp$timestamp)
train_for_timestamp <- read.csv('datasets/consumption_train.csv')
train_for_timestamp$timestamp <- as.POSIXct(train_for_timestamp$timestamp)
str(train_for_timestamp)
str(train)
train_for_timestamp <- read.csv('datasets/consumption_train.csv')
train$timestamp <- as.POSIXct(train_for_timestamp$timestamp)
train_meta_lj <- left_join(x= train, y = meta, suffix = c(".x", ".m1"))
View(head(train_meta_lj))
#test$time <- format(as.POSIXct(test$timestamp) ,format = "%H:%M:%S")
test$timestamp <- as.POSIXct(test$timestamp)
test$hour <- hour(hms(as.character(test$time)))
test$timestamp <- as.POSIXct(test$timestamp)
# 10 left join between train and meta
train_meta_lj <- left_join(x= train, y = meta, suffix = c(".x", ".m1"))
# 11 left join between test and meta
test_meta_lj <- left_join(x= test, y= meta, suffix = c(".y", ".m2"))
range(test_meta_lj$consumption, finite = 1)
min(train_meta_lj$consumption, na.rm = TRUE)
max(train_meta_lj$consumption, na.rm = TRUE)
# 18 Looking at range of temperature and consumption, eliminating NA/ Inf
range(train_meta_lj$temperature, finite = 1)
# calculating % of missing data columnwise
sort(colMeans(is.na(train_meta_lj)*100), decreasing = TRUE)  # 45% missing values of temperature
# Converting join data frames to xts object
train_ts <- xts(x = train_meta_lj, order.by = train_meta_lj$timestamp)
test_ts <- xts(x = test_meta_lj, order.by = test_meta_lj$timestamp)
colnames(train_ts)
ggplot(data = train_ts) +
geom_bar(mapping = aes(x = consumption))
table(meta$is_XXlarge)
table(meta$is_large)
table(meta$is_Xlarge)
sapply(meta, table)
# 2 Loading packages
pkgs <- c("tidyverse", "caret","zoo", "mice", 'VIM', 'e1071', 'lubrirdate')
lapply(pkgs, require, character.only= TRUE)
library(lubridate)
# 3 Importing data
meta <- read.csv('datasets/meta.csv')
# 5 summary of the data
summary(meta)
meta<- meta %>%
mutate(v = 1, sf = surface) %>%
spread(sf, v, fill = 0)
# 5 summary of the data
summary(meta)
str(meta)
# mutate_at(cols, factor)
meta %<>% mutate_at(is.numeric, as.factor)
library(tidyverse)
library(magrittr)
str(meta)
# mutate_at(cols, factor)
meta %<>% mutate_at(is.numeric, as.factor)
# mutate_at(cols, factor)
meta %<>% mutate_if(is.numeric, as.factor)
str(meta)
meta$surface <- NULL  # Removing the surface variable
# 3 Renaming dummy columns from surface
meta <- meta %>% rename(is_large = large)        # large
meta <- meta %>% rename(is_medium = medium)      # medium
meta <- meta %>% rename(is_Xlarge = 'x-large')   # xlarge
meta <- meta %>% rename(is_Xsmall = 'x-small')   # x small
meta <- meta %>% rename(is_XXlarge = 'xx-large') # xx-large
meta <- meta %>% rename(is_XXsmall = 'xx-small') # xx-small
meta <- meta %>% rename(is_small = small)        # small
meta <- meta %>% rename(is_baseTemperatureHigh = base_temperature) # base Temperature
View(meta)
meta$is_baseTemperatureHigh <- if_else(meta$is_baseTemperatureHigh == 'high', 1, 0)
View(meta)
train <- read.csv('datasets/consumption_train.csv')
train %>% filter(consumption == 0)
getwd()
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
install.packages('tubr')
install.packages('tm')
install.packages('tm', dependencies=TRUE, repos='http://cran.rstudio.com/)
dependencies=TRUE, repos='http://cran.rstudio.com/)
dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('tm', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(tubr)
library(tubr,dependencies = TRUE, repos = 'https://cran.rstudion.com')
install.packages('tubr',dependencies = TRUE, repos = 'https://cran.rstudion.com')
install.packages('tuber',dependencies = TRUE, repos = 'https://cran.rstudion.com')
library(tuber)
install.packages('tuber',dependencies = TRUE, repos = 'https://cran.rstudion.com')
source('D:/Technical/Driven Data Competition/A_Groudwork.R', echo=TRUE)
##### Import the datasets #####
train <- read_csv('datasets/consumption_train.csv')
meta <- read_csv('datasets/meta.csv')
test <- read_csv('datasets/cold_start_test.csv')
submission_format <- read_csv('datasets/submission_format.csv')
##### tidying meta data #####
# 1. Converting dummy variable for surface
meta %<>%
mutate(v = 1, sf = surface) %>%
spread(sf, v, fill = 0)
# 2. Renaming dummy columns from surface
meta %<>% rename(is_large = large)        # large
meta %<>% rename(is_medium = medium)      # medium
meta %<>% rename(is_Xlarge = 'x-large')   # xlarge
meta %<>% rename(is_Xsmall = 'x-small')   # x small
meta %<>% rename(is_XXlarge = 'xx-large') # xx-large
meta %<>% rename(is_XXsmall = 'xx-small') # xx-small
meta %<>% rename(is_small = small)        # small
meta %<>% rename(is_baseTemperatureHigh = base_temperature) # base Temperature
# 3. change high = 1 and low = 0 in base_temperature
meta$is_baseTemperatureHigh <- if_else(meta$is_baseTemperatureHigh == 'high', 1, 0)
# 4. Converting False to 0 and True to 1 in days columns
meta %<>% mutate_at(vars(ends_with('_is_day_off')),
funs(case_when(
. =='False' ~ 0,
. == 'True'~ 1)))
# 5. Converting the newly created dummy var datatype from numeric to factor
# except the series_id column:
meta %<>% mutate_at(vars(-series_id), funs(as.factor(.)))
# 6. Dropping column surface
meta$surface <- NULL
# Column(s) to add
# Extracting hour from timestamp
train$hour <-
# Column(s) to drop
train$X <- NULL
# 3 take a look at the top rows of the data
View(head(meta))
View(head(train))
# Column(s) to add
# Extracting hour from timestamp
train$hour <-
# Column(s) to drop
train$X <- NULL
View(head(train))
str(train)  # 509376 obs. of  5 variables
colnames(train)
# Column(s) to add
# Extracting hour from timestamp
train$hour <-
# Column(s) to drop
train$X1 <- NULL
colnames(train)
View(submission_format)
View(test)
test <- c(1:6)
test <- read_csv('datasets/cold_start_test.csv')
x <- 1:6
x
var(x)
?var
3*81
27*8
x
x <- 0:6
var(x)
sd(x)
ave(x)
which(test$series_id == 100735)
View(submission_format)
install.packages('feather')
devtools::install_github("wesm/feather/R")
install.packages('feather', dependency = TRUE, repos = "https://cran.rstudion.com")
install.packages('feather', dependencies=TRUE, repos='http://cran.rstudio.com/')
devtools::install_github("wesm/feather/R")
library(devtools)
devtools::install_github("wesm/feather/R")
install.packages("https://cran.r-project.org/bin/windows/contrib/3.4/feather_0.3.1.zip", repos =NULL)
library(feather)
version
install.packages("https://cran.r-project.org/bin/windows/contrib/3.5.1/feather_0.3.1.zip", repos =NULL)
install.packages("https://cran.r-project.org/bin/windows/contrib/3.5/feather_0.3.1.zip", repos =NULL)
